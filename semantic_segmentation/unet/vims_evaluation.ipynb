{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08639185",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import logging\n",
    "import rasterio\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from os.path import dirname as up\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "path_cur = os.path.abspath(os.getcwd())\n",
    "\n",
    "sys.path.append(path_cur)\n",
    "from unet import UNet\n",
    "from vims_dataloader import GenDEBRIS, bands_mean, bands_std\n",
    "\n",
    "sys.path.append(os.path.join(up(up(path_cur)), 'utils'))\n",
    "\n",
    "from vims_metrics import Evaluation, confusion_matrix\n",
    "from vims_assets import labels\n",
    "from pathlib import Path\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "root_path = up(up(path_cur))\n",
    "\n",
    "logging.basicConfig(filename=os.path.join(root_path, 'logs','evaluating_unet.log'), filemode='a',level=logging.INFO, format='%(name)s - %(levelname)s - %(message)s')\n",
    "logging.info('*'*10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "671d1086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/rapids/notebooks/sciclone/geograd/Miranda/github/marine-debris.github.io/semantic_segmentation/unet'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02d7e8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(options):\n",
    "    # Transformations\n",
    "    \n",
    "    transform_test = transforms.Compose([transforms.ToTensor()])\n",
    "    standardization = transforms.Normalize(bands_mean, bands_std)\n",
    "    \n",
    "    # Construct Data loader\n",
    "\n",
    "    dataset_test = GenDEBRIS('test', transform=transform_test, standardization = standardization, agg_to_water = options['agg_to_water'])\n",
    "\n",
    "    test_loader = DataLoader(   dataset_test, \n",
    "                                batch_size = options['batch'], \n",
    "                                shuffle = False)\n",
    "    \n",
    "    global labels\n",
    "    # Aggregate Distribution Mixed Water, Wakes, Cloud Shadows, Waves with Marine Water\n",
    "\n",
    "#     if options['agg_to_water']:\n",
    "#         labels = labels[:-4] # Drop Mixed Water, Wakes, Cloud Shadows, Waves\n",
    "\n",
    "#     # Use gpu or cpu\n",
    "#     if torch.cuda.is_available():\n",
    "#         device = torch.device(\"cuda\")\n",
    "#     else:\n",
    "#         device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "    device = torch.device(\"cpu\")\n",
    "        \n",
    "    model = UNet(input_bands = options['input_channels'], \n",
    "                 output_classes = options['output_channels'], \n",
    "                 hidden_channels = options['hidden_channels'])\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # Load model from specific epoch to continue the training or start the evaluation\n",
    "    model_file = options['model_path']\n",
    "    logging.info('Loading model files from folder: %s' % model_file)\n",
    "\n",
    "    checkpoint = torch.load(model_file, map_location = device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "\n",
    "    del checkpoint  # dereference\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    y_true = []\n",
    "    y_predicted = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (image, target) in tqdm(test_loader, desc=\"testing\"):\n",
    "\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            logits = model(image)\n",
    "\n",
    "            # Accuracy metrics only on annotated pixels\n",
    "            logits = torch.movedim(logits, (0,1,2,3), (0,3,1,2))\n",
    "            logits = logits.reshape((-1,options['output_channels']))\n",
    "            target = target.reshape(-1)\n",
    "            mask = target != -1\n",
    "            logits = logits[mask]\n",
    "            target = target[mask]\n",
    "            \n",
    "            probs = torch.nn.functional.softmax(logits, dim=1).cpu().numpy()\n",
    "            target = target.cpu().numpy()\n",
    "            \n",
    "            y_predicted += probs.argmax(1).tolist()\n",
    "            y_true += target.tolist()\n",
    "        \n",
    "        ####################################################################\n",
    "        # Save Scores to the .log file                                     #\n",
    "        ####################################################################\n",
    "        acc = Evaluation(y_predicted, y_true)\n",
    "        logging.info(\"\\n\")\n",
    "        logging.info(\"STATISTICS: \\n\")\n",
    "        logging.info(\"Evaluation: \" + str(acc))\n",
    "        print(\"Evaluation: \" + str(acc))\n",
    "        \"\"\"\n",
    "        Confusion matrix whose i-th row and j-th column entry indicates the number of samples with true label \n",
    "        You being i-th class and predicted label being j-th class.\n",
    "        \"\"\"\n",
    "        conf_mat = confusion_matrix(y_true, y_predicted, labels)\n",
    "        \n",
    "        logging.info(\"Confusion Matrix:  \\n\" + str(conf_mat.to_string()))\n",
    "        print(\"Confusion Matrix:  \\n\" + str(conf_mat.to_string()))\n",
    "        \n",
    "        if options['predict_masks']:\n",
    "            \n",
    "            path = os.path.join(up(up(root_path)), 'VIMS', 'NAIP', 'VA_NAIP_2018_8977', 'test')\n",
    "            ROIs = [file for file in os.listdir(path) if file.split('.')[-1]=='tif']\n",
    "\n",
    "            impute_nan = np.tile(bands_mean, (256,256,1))\n",
    "                        \n",
    "            for roi in tqdm(ROIs):\n",
    "            \n",
    "#                 roi_folder = '_'.join(['S2'] + roi.split('_')[:-1])             # Get Folder Name\n",
    "#                 roi_name = '_'.join(['S2'] + roi.split('_'))                    # Get File Name\n",
    "#                 roi_file = os.path.join(path, roi_folder,roi_name + '.tif')     # Get File path\n",
    "                \n",
    "                roi_file = os.path.join(path, roi)\n",
    "                os.makedirs(options['gen_masks_path'], exist_ok=True)\n",
    "            \n",
    "                output_image = os.path.join(options['gen_masks_path'], os.path.basename(roi_file).split('.tif')[0] + '_unet.tif')\n",
    "            \n",
    "                # Read metadata of the initial image\n",
    "                with rasterio.open(roi_file, mode ='r') as src:\n",
    "                    tags = src.tags().copy()\n",
    "                    meta = src.meta\n",
    "                    image = src.read()\n",
    "                    image = np.moveaxis(image, (0, 1, 2), (2, 0, 1))\n",
    "                    dtype = src.read(1).dtype\n",
    "            \n",
    "                # Update meta to reflect the number of layers\n",
    "                meta.update(count = 1)\n",
    "            \n",
    "                # Write it\n",
    "                with rasterio.open(output_image, 'w', **meta) as dst:\n",
    "                    \n",
    "                    # Preprocessing before prediction\n",
    "                    nan_mask = np.isnan(image)\n",
    "                    image[nan_mask] = impute_nan[nan_mask]\n",
    "            \n",
    "                    image = transform_test(image)\n",
    "                    \n",
    "                    image = standardization(image)\n",
    "                    \n",
    "                    # Image to Cuda if exist\n",
    "                    image = image.to(device)\n",
    "            \n",
    "                    # Predictions\n",
    "                    logits = model(image.unsqueeze(0))\n",
    "            \n",
    "                    probs = torch.nn.functional.softmax(logits.detach(), dim=1).cpu().numpy()\n",
    "            \n",
    "                    probs = probs.argmax(1).squeeze()+1\n",
    "                    \n",
    "                    # Write the mask with georeference\n",
    "                    dst.write_band(1, probs.astype(dtype).copy()) # In order to be in the same dtype\n",
    "                    dst.update_tags(**tags)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e09a98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64366494",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(path_cur, 'trained_models', '200', 'model.pth')\n",
    "gen_masks_path = os.path.join(up(up(root_path)), 'VIMS', 'NAIP', 'VA_NAIP_2018_8977', 'test_masks')\n",
    "\n",
    "\n",
    "options = {'agg_to_water': True, 'batch': 5, \n",
    "          'input_channels': 4, 'output_channels': 4, 'hidden_channels': 16,\n",
    "          'model_path': model_path, 'predict_masks': True, 'gen_masks_path':gen_masks_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4428c75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load test set to memory: 100%|██████████| 2487/2487 [00:11<00:00, 211.09it/s]\n",
      "testing: 100%|██████████| 498/498 [00:40<00:00, 12.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: {'macroPrec': 0.549332248723822, 'microPrec': 0.7432177201083239, 'weightPrec': 0.7488074901774064, 'macroRec': 0.6600512597266295, 'microRec': 0.7432177201083239, 'weightRec': 0.7432177201083239, 'macroF1': 0.5879440408733589, 'microF1': 0.7432177201083239, 'weightF1': 0.7420993987726012, 'subsetAcc': 0.7432177201083239, 'IoU': 0.43430327083335263}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2487 [00:00<01:35, 26.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:  \n",
      "                     Bulkhead Or Sea Wall    Rip Rap    Groin Breakwater        Sum Recall\n",
      "Bulkhead Or Sea Wall            1650307.0   346570.0   2975.0     6868.0  2006720.0   0.82\n",
      "Rip Rap                          613497.0  1246990.0   6236.0    16882.0  1883605.0   0.66\n",
      "Groin                               401.0     2532.0   5728.0     1006.0     9667.0   0.59\n",
      "Breakwater                         1040.0     7388.0   2449.0    14028.0    24905.0   0.56\n",
      "Sum                             2265245.0  1603480.0  17388.0    38784.0       mPA:   0.66\n",
      "IoU                                  0.63       0.56     0.27       0.28      mIoU:   0.43\n",
      "Precision                            0.73       0.78     0.33       0.36        OA:   0.74\n",
      "F1-score                             0.77       0.72     0.42       0.44  F1-macro:   0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2487/2487 [01:22<00:00, 30.27it/s]\n"
     ]
    }
   ],
   "source": [
    "main(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a2ecfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba54beb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
