{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4347940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import logging\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from os.path import dirname as up\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "path_cur = os.path.abspath(os.getcwd())\n",
    "\n",
    "sys.path.append(path_cur)\n",
    "from unet import UNet\n",
    "\n",
    "\n",
    "from vims_dataloader import GenDEBRIS, RandomRotationTransform , class_distr, gen_weights, bands_mean, bands_std\n",
    "\n",
    "sys.path.append(os.path.join(up(up(path_cur)), 'utils'))\n",
    "from vims_metrics import Evaluation\n",
    "\n",
    "root_path = up(up(path_cur))\n",
    "\n",
    "logging.basicConfig(filename=os.path.join(root_path, 'logs','log_unet.log'), filemode='a',level=logging.INFO, format='%(name)s - %(levelname)s - %(message)s')\n",
    "logging.info('*'*10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1641f5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afd25b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "When generating random numbers, the seed between CPU and GPU is not synchronized. \n",
    "Hence, we need to set the seed on the GPU separately to ensure a reproducible code. \n",
    "Note that due to different GPU architectures, running the same code on different GPUs does not guarantee the same random numbers. \n",
    "Still, we don’t want that our code gives us a different output every time we run it on the exact same hardware. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def seed_all(seed):\n",
    "    # Pytorch Reproducibility\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "def seed_worker(worker_id):\n",
    "    # DataLoader Workers Reproducibility\n",
    "    worker_seed = torch.initial_seed() % 2**32 # Returns the initial seed for generating random numbers as a Python long: torch.initial_seed()\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed) # generate the same value of randomized value for reproduction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76334f68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8bc7fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(options):\n",
    "    # Reproducibility\n",
    "    # Limit the number of sources of nondeterministic behavior \n",
    "    seed_all(0)\n",
    "    \n",
    "    # Creates and returns a generator object that manages the state of the algorithm which produces pseudo random numbers. Used as a keyword argument in many In-place random sampling functions.\n",
    "    g = torch.Generator() \n",
    "    g.manual_seed(0)\n",
    "    \n",
    "    # Tensorboard: \n",
    "    # The SummaryWriter class is the entry to log data for consumption and visualization by TensorBoard: https://pytorch.org/docs/stable/tensorboard.html\n",
    "\n",
    "    writer = SummaryWriter(os.path.join(root_path, 'logs', options['tensorboard']))\n",
    "    \n",
    "    # Transformations\n",
    "    \n",
    "    transform_train = transforms.Compose([transforms.ToTensor(),\n",
    "                                    RandomRotationTransform([-90, 0, 90, 180]),\n",
    "                                    transforms.RandomHorizontalFlip()])\n",
    "    \n",
    "    transform_test = transforms.Compose([transforms.ToTensor()])\n",
    "    \n",
    "#     standardization = transforms.Normalize(bands_mean, bands_std)\n",
    "\n",
    "    standardization = transforms.Normalize(bands_mean, bands_std)\n",
    "    \n",
    "    # Construct Data loader\n",
    "    \n",
    "    if options['mode']=='train':\n",
    "        \n",
    "        dataset_train = GenDEBRIS('train', transform=transform_train, standardization = standardization, agg_to_water = options['agg_to_water'])\n",
    "        dataset_test = GenDEBRIS('val', transform=transform_test, standardization = standardization, agg_to_water = options['agg_to_water'])\n",
    "        \n",
    "        train_loader = DataLoader(  dataset_train, \n",
    "                                    batch_size = options['batch'], \n",
    "                                    shuffle = True,\n",
    "                                    num_workers = 0, #options['num_workers'], #1\n",
    "                                    pin_memory = options['pin_memory'], #False\n",
    "#                                     prefetch_factor = options['prefetch_factor'], #1\n",
    "#                                     persistent_workers= options['persistent_workers'], #True\n",
    "                                    worker_init_fn=seed_worker,\n",
    "                                    generator=g) #If not None, this RNG (random number generator) will be used by RandomSampler to generate random indexes and multiprocessing \n",
    "                                                 #to generate base_seed for workers. (default: None)\n",
    "        \n",
    "        test_loader = DataLoader(   dataset_test, \n",
    "                                    batch_size = options['batch'], \n",
    "                                    shuffle = False,\n",
    "                                    num_workers = 0, #options['num_workers'],\n",
    "                                    pin_memory = options['pin_memory'],\n",
    "#                                     prefetch_factor = options['prefetch_factor'],\n",
    "#                                     persistent_workers= options['persistent_workers'],\n",
    "                                    worker_init_fn=seed_worker,\n",
    "                                    generator=g)\n",
    "\n",
    "        \n",
    "    elif options['mode']=='test':\n",
    "        \n",
    "        dataset_test = GenDEBRIS('test', transform=transform_test, standardization = standardization, agg_to_water = options['agg_to_water'])\n",
    "    \n",
    "        test_loader = DataLoader(   dataset_test, \n",
    "                                    batch_size = options['batch'], \n",
    "                                    shuffle = False,\n",
    "                                    num_workers = options['num_workers'],\n",
    "                                    pin_memory = options['pin_memory'],\n",
    "                                    prefetch_factor = options['prefetch_factor'],\n",
    "                                    persistent_workers= options['persistent_workers'],\n",
    "                                    worker_init_fn=seed_worker,\n",
    "                                    generator=g)\n",
    "    else:\n",
    "        raise                        \n",
    "    \n",
    "    # Use gpu or cpu\n",
    "#     if torch.cuda.is_available():\n",
    "#         device = torch.device(\"cuda\")\n",
    "#     else:\n",
    "#         device = torch.device(\"cpu\")\n",
    "    \n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    \n",
    "#     device = torch.device(\"cpu\")\n",
    "        \n",
    "    model = UNet(input_bands = options['input_channels'], \n",
    "                 output_classes = options['output_channels'], \n",
    "                 hidden_channels = options['hidden_channels'])\n",
    "        \n",
    "#     model = smp.Unet(encoder_name=\"resnet34\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "#                     encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "#                     in_channels=options['input_channels'],                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "#                     classes=options['output_channels'])                      # model output channels (number of classes in your dataset)) \n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # Load model from specific epoch to continue the training or start the evaluation\n",
    "    if options['resume_from_epoch'] > 1:\n",
    "        \n",
    "        resume_model_dir = os.path.join(options['checkpoint_path'], str(options['resume_from_epoch']))\n",
    "        model_file = os.path.join(resume_model_dir, 'model.pth')\n",
    "        logging.info('Loading model files from folder: %s' % model_file)\n",
    "\n",
    "        checkpoint = torch.load(model_file, map_location = device)\n",
    "        model.load_state_dict(checkpoint)\n",
    "\n",
    "        del checkpoint  # dereference\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    global class_distr\n",
    "    # Aggregate Distribution Mixed Water, Wakes, Cloud Shadows, Waves with Marine Water\n",
    "\n",
    "#     if options['agg_to_water']:\n",
    "#         agg_distr = sum(class_distr[-4:]) # Density of Mixed Water, Wakes, Cloud Shadows, Waves\n",
    "#         class_distr[6] += agg_distr       # To Water\n",
    "#         class_distr = class_distr[:-4]    # Drop Mixed Water, Wakes, Cloud Shadows, Waves\n",
    "\n",
    "    # Weighted Cross Entropy Loss & adam optimizer\n",
    "    weight = gen_weights(class_distr, c = options['weight_param'])\n",
    "    \n",
    "    # nn.CrossEntropyLoss: This criterion computes the cross entropy loss between input and target\n",
    "    # CrossEntropyLoss()损失函数交叉熵主要是用来判定实际的输出与期望的输出的接近程度\n",
    "    # https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
    "    criterion = torch.nn.CrossEntropyLoss(ignore_index=-1, reduction= 'mean', weight=weight.to(device))\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=options['lr'], weight_decay=options['decay']) # weight_decay: (L2 penalty)\n",
    "\n",
    "    # Learning Rate scheduler\n",
    "    if options['reduce_lr_on_plateau']==1:\n",
    "        \n",
    "        \"\"\"\n",
    "        Reduce learning rate when a metric has stopped improving. \n",
    "        Models often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates. \n",
    "        This scheduler reads a metrics quantity and if no improvement is seen for a ‘patience’ number of epochs, the learning rate is reduced.\n",
    "        \"\"\"\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n",
    "    else:\n",
    "        \"\"\"\n",
    "        Decays the learning rate of each parameter group by gamma once the number of epoch reaches one of the milestones. \n",
    "        Notice that such decay can happen simultaneously with other changes to the learning rate from outside this scheduler. \n",
    "        When last_epoch=-1 (default), sets initial lr as lr.\n",
    "        \"\"\"\n",
    "        scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, options['lr_steps'], gamma=0.1, verbose=True)\n",
    "\n",
    "    # Start training\n",
    "    start = options['resume_from_epoch'] + 1\n",
    "    epochs = options['epochs']\n",
    "    eval_every = options['eval_every'] #1\n",
    "\n",
    "    \n",
    "    # Write model-graph to Tensorboard\n",
    "    if options['mode']=='train':\n",
    "        dataiter = iter(train_loader)\n",
    "        image_temp, _ = dataiter.next()\n",
    "        writer.add_graph(model, image_temp.to(device)) # add graph data to summary\n",
    "        \n",
    "        ###############################################################\n",
    "        # Start Training                                              #\n",
    "        ###############################################################\n",
    "        model.train()\n",
    "        \n",
    "        for epoch in range(start, epochs+1):\n",
    "            training_loss = []\n",
    "            training_batches = 0\n",
    "            \n",
    "            i_board = 0\n",
    "            for (image, target) in tqdm(train_loader, desc=\"training\"):\n",
    "                \n",
    "                image = image.to(device)\n",
    "                target = target.to(device)\n",
    "    \n",
    "                optimizer.zero_grad() # zero the parameter gradients\n",
    "                \n",
    "                logits = model(image) # model predict tag\n",
    "                \n",
    "                loss = criterion(logits, target) # calculate the loss between the input (predict tag) and target tag\n",
    "    \n",
    "                loss.backward()\n",
    "    \n",
    "                training_batches += target.shape[0]\n",
    "    \n",
    "                training_loss.append((loss.data*target.shape[0]).tolist())\n",
    "                \n",
    "                optimizer.step()\n",
    "                \n",
    "                # Write running loss\n",
    "                writer.add_scalar('training loss', loss , (epoch - 1) * len(train_loader)+i_board)\n",
    "                i_board+=1\n",
    "            \n",
    "            logging.info(\"Training loss was: \" + str(sum(training_loss) / training_batches))\n",
    "            \n",
    "            ###############################################################\n",
    "            # Start Evaluation                                            #\n",
    "            ###############################################################\n",
    "            \n",
    "            if epoch % eval_every == 0 or epoch==1:\n",
    "                model.eval()\n",
    "    \n",
    "                test_loss = []\n",
    "                test_batches = 0\n",
    "                y_true = []\n",
    "                y_predicted = []\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    for (image, target) in tqdm(test_loader, desc=\"testing\"):\n",
    "    \n",
    "                        image = image.to(device)\n",
    "                        target = target.to(device)\n",
    "    \n",
    "                        logits = model(image)\n",
    "                        \n",
    "                        loss = criterion(logits, target)\n",
    "                                    \n",
    "                        # Accuracy metrics only on annotated pixels\n",
    "                        logits = torch.movedim(logits, (0,1,2,3), (0,3,1,2))\n",
    "                        logits = logits.reshape((-1,options['output_channels']))\n",
    "                        target = target.reshape(-1)\n",
    "                        mask = target != -1\n",
    "                        logits = logits[mask]\n",
    "                        target = target[mask]\n",
    "                        \n",
    "                        probs = torch.nn.functional.softmax(logits, dim=1).cpu().numpy()\n",
    "                        target = target.cpu().numpy()\n",
    "                        \n",
    "                        test_batches += target.shape[0]\n",
    "                        test_loss.append((loss.data*target.shape[0]).tolist())\n",
    "                        y_predicted += probs.argmax(1).tolist()\n",
    "                        y_true += target.tolist()\n",
    "                            \n",
    "                        \n",
    "                    y_predicted = np.asarray(y_predicted)\n",
    "                    y_true = np.asarray(y_true)\n",
    "                    \n",
    "                    ####################################################################\n",
    "                    # Save Scores to the .log file and visualize also with tensorboard #\n",
    "                    ####################################################################\n",
    "                    \n",
    "                    acc = Evaluation(y_predicted, y_true)\n",
    "                    logging.info(\"\\n\")\n",
    "                    logging.info(\"Test loss was: \" + str(sum(test_loss) / test_batches))\n",
    "                    logging.info(\"STATISTICS AFTER EPOCH \" +str(epoch) + \": \\n\")\n",
    "                    logging.info(\"Evaluation: \" + str(acc))\n",
    "    \n",
    "    \n",
    "                    logging.info(\"Saving models\")\n",
    "                    model_dir = os.path.join(options['checkpoint_path'], str(epoch))\n",
    "                    os.makedirs(model_dir, exist_ok=True)\n",
    "                    torch.save(model.state_dict(), os.path.join(model_dir, 'model.pth'))\n",
    "                    \n",
    "                    writer.add_scalars('Loss per epoch', {'Test loss':sum(test_loss) / test_batches, \n",
    "                                                          'Train loss':sum(training_loss) / training_batches}, \n",
    "                                       epoch)\n",
    "                    \n",
    "                    writer.add_scalar('Precision/test macroPrec', acc[\"macroPrec\"] , epoch)\n",
    "                    writer.add_scalar('Precision/test microPrec', acc[\"microPrec\"] , epoch)\n",
    "                    writer.add_scalar('Precision/test weightPrec', acc[\"weightPrec\"] , epoch)\n",
    "                    \n",
    "                    writer.add_scalar('Recall/test macroRec', acc[\"macroRec\"] , epoch)\n",
    "                    writer.add_scalar('Recall/test microRec', acc[\"microRec\"] , epoch)\n",
    "                    writer.add_scalar('Recall/test weightRec', acc[\"weightRec\"] , epoch)\n",
    "                    \n",
    "                    writer.add_scalar('F1/test macroF1', acc[\"macroF1\"] , epoch)\n",
    "                    writer.add_scalar('F1/test microF1', acc[\"microF1\"] , epoch)\n",
    "                    writer.add_scalar('F1/test weightF1', acc[\"weightF1\"] , epoch)\n",
    "                    \n",
    "                    writer.add_scalar('IoU/test MacroIoU', acc[\"IoU\"] , epoch)\n",
    "                    \n",
    "    \n",
    "                if options['reduce_lr_on_plateau'] == 1:\n",
    "                    scheduler.step(sum(test_loss) / test_batches)\n",
    "                else:\n",
    "                    scheduler.step()\n",
    "                    \n",
    "                model.train()\n",
    "               \n",
    "    # CODE ONLY FOR EVALUATION - TESTING MODE !\n",
    "    elif options['mode']=='test':\n",
    "        \n",
    "        model.eval()\n",
    "\n",
    "        test_loss = []\n",
    "        test_batches = 0\n",
    "        y_true = []\n",
    "        y_predicted = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for (image, target) in tqdm(test_loader, desc=\"testing\"):\n",
    "\n",
    "                image = image.to(device)\n",
    "                target = target.to(device)\n",
    "\n",
    "                logits = model(image)\n",
    "                \n",
    "                loss = criterion(logits, target)\n",
    "\n",
    "                # Accuracy metrics only on annotated pixels\n",
    "                logits = torch.movedim(logits, (0,1,2,3), (0,3,1,2))\n",
    "                logits = logits.reshape((-1,options['output_channels']))\n",
    "                target = target.reshape(-1)\n",
    "                mask = target != -1\n",
    "                logits = logits[mask]\n",
    "                target = target[mask]\n",
    "                \n",
    "                probs = torch.nn.functional.softmax(logits, dim=1).cpu().numpy()\n",
    "                target = target.cpu().numpy()\n",
    "                \n",
    "                test_batches += target.shape[0]\n",
    "                test_loss.append((loss.data*target.shape[0]).tolist())\n",
    "                y_predicted += probs.argmax(1).tolist()\n",
    "                y_true += target.tolist()\n",
    "                \n",
    "            y_predicted = np.asarray(y_predicted)\n",
    "            y_true = np.asarray(y_true)\n",
    "            \n",
    "            ####################################################################\n",
    "            # Save Scores to the .log file                                     #\n",
    "            ####################################################################\n",
    "            acc = Evaluation(y_predicted, y_true)\n",
    "            logging.info(\"\\n\")\n",
    "            logging.info(\"Test loss was: \" + str(sum(test_loss) / test_batches))\n",
    "            logging.info(\"STATISTICS: \\n\")\n",
    "            logging.info(\"Evaluation: \" + str(acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7536acf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(path_cur, 'trained_models')\n",
    "\n",
    "options = {'agg_to_water': True, 'mode': 'train', 'epochs':200, 'batch': 5, 'resume_from_epoch': 0,\n",
    "          'input_channels': 4, 'output_channels': 4, 'hidden_channels': 16, 'weight_param': 1.03,\n",
    "          'lr': 2e-4, 'decay': 0, 'reduce_lr_on_plateau': 0, 'lr_steps':'[40]', \n",
    "          'checkpoint_path': checkpoint_path, 'eval_every': 1, 'num_workers': 0, 'pin_memory': False,\n",
    "          'prefetch_factor': 1, 'persistent_workers': True, 'tensorboard': 'tsboard_segm'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19392cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load train set to memory: 100%|██████████| 2583/2583 [00:12<00:00, 211.10it/s]\n",
      "Load val set to memory: 100%|██████████| 215/215 [00:00<00:00, 229.61it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6753f2a56966>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-708d4f892ea4>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(options)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;31m#                     classes=options['output_channels'])                      # model output channels (number of classes in your dataset))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# Load model from specific epoch to continue the training or start the evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    895\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    896\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 897\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "main(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95ced40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f881e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe39b0f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
