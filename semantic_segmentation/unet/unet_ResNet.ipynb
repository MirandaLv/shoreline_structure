{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ed26fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import logging\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from os.path import dirname as up\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "path_cur = os.path.abspath(os.getcwd())\n",
    "\n",
    "sys.path.append(path_cur)\n",
    "\n",
    "from vims_dataloader_backbone import GenDEBRIS\n",
    "\n",
    "sys.path.append(os.path.join(up(up(path_cur)), 'utils'))\n",
    "from vims_metrics import Evaluation\n",
    "\n",
    "root_path = up(up(path_cur))\n",
    "\n",
    "# logging.basicConfig(filename=os.path.join(root_path, 'logs_paper', 'log_unet.log'), filemode='a',level=logging.INFO, format='%(name)s - %(levelname)s - %(message)s')\n",
    "# logging.info('*'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80437de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/rapids/notebooks/sciclone/geograd/Miranda/github/shoreline_structure'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7722e8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "When generating random numbers, the seed between CPU and GPU is not synchronized. \n",
    "Hence, we need to set the seed on the GPU separately to ensure a reproducible code. \n",
    "Note that due to different GPU architectures, running the same code on different GPUs does not guarantee the same random numbers. \n",
    "Still, we don’t want that our code gives us a different output every time we run it on the exact same hardware. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def seed_all(seed):\n",
    "    # Pytorch Reproducibility\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "def seed_worker(worker_id):\n",
    "    # DataLoader Workers Reproducibility\n",
    "    worker_seed = torch.initial_seed() % 2**32 # Returns the initial seed for generating random numbers as a Python long: torch.initial_seed()\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed) # generate the same value of randomized value for reproduction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71dd184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ddcbac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(options):\n",
    "    # Reproducibility\n",
    "    # Limit the number of sources of nondeterministic behavior \n",
    "    seed_all(0)\n",
    "    \n",
    "    # Creates and returns a generator object that manages the state of the algorithm which produces pseudo random numbers. Used as a keyword argument in many In-place random sampling functions.\n",
    "    g = torch.Generator() \n",
    "    g.manual_seed(0)\n",
    "    \n",
    "    # Tensorboard: \n",
    "    # The SummaryWriter class is the entry to log data for consumption and visualization by TensorBoard: https://pytorch.org/docs/stable/tensorboard.html\n",
    "    \n",
    "    #\n",
    "#     dest_tensorboard = 'unet_{}_{}'.format(options['lr'], options['data_source']) #options['epochs']\n",
    "    writer = SummaryWriter(os.path.join(root_path, 'logs_backbone_paper', options[\"dest_tensorboard\"]))\n",
    "    \n",
    "    checkpoint_path = os.path.join(options['checkpoint_root_path'], options[\"dest_tensorboard\"])\n",
    "    \n",
    "    # Transformations\n",
    "    \n",
    "#     transform_train = transforms.Compose([transforms.ToTensor(),\n",
    "#                                     RandomRotationTransform([-90, 0, 90, 180]),\n",
    "#                                     transforms.RandomHorizontalFlip()])\n",
    "    \n",
    "    transform_train = transforms.Compose([transforms.ToTensor()])\n",
    "    transform_test = transforms.Compose([transforms.ToTensor()])\n",
    "    \n",
    "    # Standardization\n",
    "    standardization = None # transforms.Normalize(bands_mean, bands_std)\n",
    "    \n",
    "    # Construct Data loader\n",
    "    \n",
    "    if options['mode']=='train':\n",
    "        \n",
    "        dataset_train = GenDEBRIS('train', transform=transform_train, standardization = standardization, data_name = options[\"data_source\"])\n",
    "        dataset_test = GenDEBRIS('val', transform=transform_test, standardization = standardization, data_name = options[\"data_source\"])\n",
    "        \n",
    "        train_loader = DataLoader(  dataset_train, \n",
    "                                    batch_size = options['batch'], \n",
    "                                    shuffle = True,\n",
    "                                    num_workers = 0,\n",
    "                                    pin_memory = False,\n",
    "                                    worker_init_fn=seed_worker,\n",
    "                                    generator=g) #If not None, this RNG (random number generator) will be used by RandomSampler to generate random indexes and multiprocessing \n",
    "                                                 #to generate base_seed for workers. (default: None)\n",
    "        \n",
    "        test_loader = DataLoader(   dataset_test, \n",
    "                                    batch_size = options['batch'], \n",
    "                                    shuffle = False,\n",
    "                                    num_workers = 0,\n",
    "                                    pin_memory = False,\n",
    "                                    worker_init_fn=seed_worker,\n",
    "                                    generator=g)\n",
    "\n",
    "        \n",
    "    elif options['mode']=='test':\n",
    "        \n",
    "        dataset_test = GenDEBRIS('test', transform=transform_test, standardization = standardization, data_name = options[\"data_source\"])\n",
    "    \n",
    "        test_loader = DataLoader(   dataset_test, \n",
    "                                    batch_size = options['batch'], \n",
    "                                    shuffle = False,\n",
    "                                    num_workers = 0,\n",
    "                                    worker_init_fn=seed_worker,\n",
    "                                    generator=g)\n",
    "    else:\n",
    "        raise\n",
    "    \n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "#     device = torch.device(\"cpu\")\n",
    "    \n",
    "    model = smp.Unet(options[\"backbone\"],\n",
    "                     encoder_weights=options[\"encoder_weights\"],\n",
    "                     in_channels=options[\"input_channels\"],\n",
    "                     classes=options[\"output_channels\"],\n",
    "                    activation='softmax')\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # Load model from specific epoch to continue the training or start the evaluation\n",
    "    if options['resume_from_epoch'] > 1:\n",
    "        \n",
    "        resume_model_dir = os.path.join(checkpoint_path, str(options['resume_from_epoch']))\n",
    "        model_file = os.path.join(resume_model_dir, 'model.pth')\n",
    "        logging.info('Loading model files from folder: %s' % model_file)\n",
    "\n",
    "        checkpoint = torch.load(model_file, map_location = device)\n",
    "        model.load_state_dict(checkpoint)\n",
    "\n",
    "        del checkpoint  # dereference\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    global class_distr\n",
    "    # Aggregate Distribution Mixed Water, Wakes, Cloud Shadows, Waves with Marine Water\n",
    "\n",
    "#     if options['agg_to_water']:\n",
    "#         agg_distr = sum(class_distr[-4:]) # Density of Mixed Water, Wakes, Cloud Shadows, Waves\n",
    "#         class_distr[6] += agg_distr       # To Water\n",
    "#         class_distr = class_distr[:-4]    # Drop Mixed Water, Wakes, Cloud Shadows, Waves\n",
    "\n",
    "    # Weighted Cross Entropy Loss & adam optimizer\n",
    "    weight = gen_weights(class_distr, c = options['weight_param'])\n",
    "    \n",
    "    # nn.CrossEntropyLoss: This criterion computes the cross entropy loss between input and target\n",
    "    # CrossEntropyLoss()损失函数交叉熵主要是用来判定实际的输出与期望的输出的接近程度\n",
    "    # https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
    "    criterion = torch.nn.CrossEntropyLoss(ignore_index=-1, reduction= 'mean', weight=weight.to(device))\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=options['lr'], weight_decay=options['decay']) # weight_decay: (L2 penalty)\n",
    "\n",
    "    # Learning Rate scheduler\n",
    "    if options['reduce_lr_on_plateau']==1:\n",
    "        \n",
    "        \"\"\"\n",
    "        Reduce learning rate when a metric has stopped improving. \n",
    "        Models often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates. \n",
    "        This scheduler reads a metrics quantity and if no improvement is seen for a ‘patience’ number of epochs, the learning rate is reduced.\n",
    "        \"\"\"\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n",
    "    else:\n",
    "        \"\"\"\n",
    "        Decays the learning rate of each parameter group by gamma once the number of epoch reaches one of the milestones. \n",
    "        Notice that such decay can happen simultaneously with other changes to the learning rate from outside this scheduler. \n",
    "        When last_epoch=-1 (default), sets initial lr as lr.\n",
    "        \"\"\"\n",
    "        scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, options['lr_steps'], gamma=0.1, verbose=True)\n",
    "\n",
    "    # Start training\n",
    "    start = options['resume_from_epoch'] + 1\n",
    "    epochs = options['epochs']\n",
    "    eval_every = options['eval_every'] #1\n",
    "\n",
    "    \n",
    "    # Write model-graph to Tensorboard\n",
    "    if options['mode']=='train':\n",
    "        dataiter = iter(train_loader)\n",
    "        image_temp, _ = dataiter.next().values()\n",
    "        \n",
    "        writer.add_graph(model, image_temp.to(device)) # add graph data to summary\n",
    "        \n",
    "        ###############################################################\n",
    "        # Start Training                                              #\n",
    "        ###############################################################\n",
    "        model.train()\n",
    "        \n",
    "        for epoch in range(start, epochs+1):\n",
    "            training_loss = []\n",
    "            training_batches = 0\n",
    "            \n",
    "            i_board = 0\n",
    "#             for (image, target) in tqdm(train_loader.values(), desc=\"training\"):\n",
    "\n",
    "            for (batch_idx, batch_val) in enumerate(tqdm(train_loader, desc=\"training\")):\n",
    "                \n",
    "                image = batch_val['image'].to(device)\n",
    "                target = batch_val['mask'].to(device)\n",
    "    \n",
    "                optimizer.zero_grad() # zero the parameter gradients\n",
    "                \n",
    "                logits = model(image) # model predict tag\n",
    "                \n",
    "                loss = criterion(logits, target) # calculate the loss between the input (predict tag) and target tag\n",
    "    \n",
    "                loss.backward()\n",
    "    \n",
    "                training_batches += target.shape[0]\n",
    "    \n",
    "                training_loss.append((loss.data*target.shape[0]).tolist())\n",
    "                \n",
    "                optimizer.step()\n",
    "                \n",
    "                # Write running loss\n",
    "                writer.add_scalar('training loss', loss , (epoch - 1) * len(train_loader)+i_board)\n",
    "                i_board+=1\n",
    "            \n",
    "            logging.info(\"Training loss was: \" + str(sum(training_loss) / training_batches))\n",
    "            \n",
    "            ###############################################################\n",
    "            # Start Evaluation                                            #\n",
    "            ###############################################################\n",
    "            \n",
    "            if epoch % eval_every == 0 or epoch==1:\n",
    "                model.eval()\n",
    "    \n",
    "                test_loss = []\n",
    "                test_batches = 0\n",
    "                y_true = []\n",
    "                y_predicted = []\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                        \n",
    "                    for (batch_idx, batch_val) in enumerate(tqdm(test_loader, desc=\"testing\")):\n",
    "            \n",
    "                        image = batch_val['image'].to(device)\n",
    "                        target = batch_val['mask'].to(device)\n",
    "    \n",
    "                        logits = model(image)\n",
    "                        \n",
    "                        loss = criterion(logits, target)\n",
    "                                    \n",
    "                        # Accuracy metrics only on annotated pixels\n",
    "                        logits = torch.movedim(logits, (0,1,2,3), (0,3,1,2))\n",
    "                        logits = logits.reshape((-1,options['output_channels']))\n",
    "                        target = target.reshape(-1)\n",
    "                        mask = target != -1\n",
    "                        logits = logits[mask]\n",
    "                        target = target[mask]\n",
    "                        \n",
    "                        probs = torch.nn.functional.softmax(logits, dim=1).cpu().numpy()\n",
    "                        target = target.cpu().numpy()\n",
    "                        \n",
    "                        test_batches += target.shape[0]\n",
    "                        test_loss.append((loss.data*target.shape[0]).tolist())\n",
    "                        y_predicted += probs.argmax(1).tolist()\n",
    "                        y_true += target.tolist()\n",
    "                            \n",
    "                        \n",
    "                    y_predicted = np.asarray(y_predicted)\n",
    "                    y_true = np.asarray(y_true)\n",
    "                    \n",
    "                    ####################################################################\n",
    "                    # Save Scores to the .log file and visualize also with tensorboard #\n",
    "                    ####################################################################\n",
    "                    \n",
    "                    acc = Evaluation(y_predicted, y_true)\n",
    "                    logging.info(\"\\n\")\n",
    "                    logging.info(\"Test loss was: \" + str(sum(test_loss) / test_batches))\n",
    "                    logging.info(\"STATISTICS AFTER EPOCH \" +str(epoch) + \": \\n\")\n",
    "                    logging.info(\"Evaluation: \" + str(acc))\n",
    "    \n",
    "    \n",
    "                    logging.info(\"Saving models\")\n",
    "                    model_dir = os.path.join(checkpoint_path, str(epoch))\n",
    "                    os.makedirs(model_dir, exist_ok=True)\n",
    "                    torch.save(model.state_dict(), os.path.join(model_dir, 'model.pth'))\n",
    "                    \n",
    "                    writer.add_scalars('Loss per epoch', {'Test loss':sum(test_loss) / test_batches, \n",
    "                                                          'Train loss':sum(training_loss) / training_batches}, \n",
    "                                       epoch)\n",
    "                    \n",
    "                    writer.add_scalar('Precision/test macroPrec', acc[\"macroPrec\"] , epoch)\n",
    "                    writer.add_scalar('Precision/test microPrec', acc[\"microPrec\"] , epoch)\n",
    "                    writer.add_scalar('Precision/test weightPrec', acc[\"weightPrec\"] , epoch)\n",
    "                    \n",
    "                    writer.add_scalar('Recall/test macroRec', acc[\"macroRec\"] , epoch)\n",
    "                    writer.add_scalar('Recall/test microRec', acc[\"microRec\"] , epoch)\n",
    "                    writer.add_scalar('Recall/test weightRec', acc[\"weightRec\"] , epoch)\n",
    "                    \n",
    "                    writer.add_scalar('F1/test macroF1', acc[\"macroF1\"] , epoch)\n",
    "                    writer.add_scalar('F1/test microF1', acc[\"microF1\"] , epoch)\n",
    "                    writer.add_scalar('F1/test weightF1', acc[\"weightF1\"] , epoch)\n",
    "                    \n",
    "                    writer.add_scalar('IoU/test MacroIoU', acc[\"IoU\"] , epoch)\n",
    "                    \n",
    "    \n",
    "                if options['reduce_lr_on_plateau'] == 1:\n",
    "                    scheduler.step(sum(test_loss) / test_batches)\n",
    "                else:\n",
    "                    scheduler.step()\n",
    "                    \n",
    "                model.train()\n",
    "               \n",
    "    # CODE ONLY FOR EVALUATION - TESTING MODE !\n",
    "    elif options['mode']=='test':\n",
    "        \n",
    "        model.eval()\n",
    "\n",
    "        test_loss = []\n",
    "        test_batches = 0\n",
    "        y_true = []\n",
    "        y_predicted = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            for (batch_idx, batch_val) in enumerate(tqdm(test_loader, desc=\"testing\")):\n",
    "            \n",
    "                image = batch_val['image'].to(device)\n",
    "                target = batch_val['mask'].to(device)\n",
    "\n",
    "                image = image.to(device)\n",
    "                target = target.to(device)\n",
    "\n",
    "                logits = model(image)\n",
    "                \n",
    "                loss = criterion(logits, target)\n",
    "\n",
    "                # Accuracy metrics only on annotated pixels\n",
    "                logits = torch.movedim(logits, (0,1,2,3), (0,3,1,2))\n",
    "                logits = logits.reshape((-1,options['output_channels']))\n",
    "                target = target.reshape(-1)\n",
    "                mask = target != -1\n",
    "                logits = logits[mask]\n",
    "                target = target[mask]\n",
    "                \n",
    "                probs = torch.nn.functional.softmax(logits, dim=1).cpu().numpy()\n",
    "                target = target.cpu().numpy()\n",
    "                \n",
    "                test_batches += target.shape[0]\n",
    "                test_loss.append((loss.data*target.shape[0]).tolist())\n",
    "                y_predicted += probs.argmax(1).tolist()\n",
    "                y_true += target.tolist()\n",
    "                \n",
    "            y_predicted = np.asarray(y_predicted)\n",
    "            y_true = np.asarray(y_true)\n",
    "            \n",
    "            ####################################################################\n",
    "            # Save Scores to the .log file                                     #\n",
    "            ####################################################################\n",
    "            acc = Evaluation(y_predicted, y_true)\n",
    "            logging.info(\"\\n\")\n",
    "            logging.info(\"Test loss was: \" + str(sum(test_loss) / test_batches))\n",
    "            logging.info(\"STATISTICS: \\n\")\n",
    "            logging.info(\"Evaluation: \" + str(acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "998a5c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting dataset folder and its weights\n",
    "# ********************************************************************************************\n",
    "\n",
    "data_name = 'Image_allyear_VA_256'\n",
    "\n",
    "# # Pixel-Level class distribution for each dataset\n",
    "\"\"\"\n",
    "{'Image_allyear_merged_512': array([0.49019898, 0.44645175, 0.02657669, 0.03677258]), \n",
    " 'Image_after_2010_merged_512': array([0.45526231, 0.43276168, 0.05267328, 0.05930273]), \n",
    " 'Image_after_2010_merged_256': array([0.32490837, 0.41855632, 0.17178225, 0.08475305]), done\n",
    " 'Image_allyear_merged_256': array([0.44056167, 0.41559786, 0.09143975, 0.05240071]), done\n",
    " 'Image_allyear_merged_1024': array([0.50426896, 0.4565353 , 0.01033589, 0.02885985]),\n",
    " 'Image_after_2010_merged_1024': array([0.49582348, 0.43486081, 0.02433212, 0.04498359]),\n",
    " 'Image_after_2010_VA_512': array([0.47100772, 0.44772889, 0.01990966, 0.06135373]), \n",
    " 'Image_after_2010_VA_256': array([0.37283283, 0.48029399, 0.04961892, 0.09725425]), done\n",
    " 'Image_allyear_VA_512': array([0.49843776, 0.45395527, 0.01021636, 0.03739061]), \n",
    " 'Image_allyear_VA_256': array([0.47332474, 0.44650446, 0.02387324, 0.05629757])} \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "if data_name == 'Image_after_2010_merged_512':\n",
    "    class_distr = torch.Tensor([0.45526231, 0.43276168, 0.05267328, 0.05930273]) # 4 classes\n",
    "elif data_name == 'Image_after_2010_merged_256':\n",
    "    class_distr = torch.Tensor([0.32490837, 0.41855632, 0.17178225, 0.08475305])\n",
    "elif data_name == 'Image_after_2010_merged_1024':\n",
    "    class_distr = torch.Tensor([0.49582348, 0.43486081, 0.02433212, 0.04498359])\n",
    "elif data_name == 'Image_allyear_merged_256':\n",
    "    class_distr = torch.Tensor([0.44056167, 0.41559786, 0.09143975, 0.05240071])\n",
    "elif data_name == 'Image_allyear_merged_512':\n",
    "    class_distr = torch.Tensor([0.49019898, 0.44645175, 0.02657669, 0.03677258])\n",
    "elif data_name == 'Image_allyear_merged_1024':\n",
    "    class_distr = torch.Tensor([0.50426896, 0.4565353 , 0.01033589, 0.02885985])\n",
    "elif data_name == 'Image_after_2010_VA_512':\n",
    "    class_distr = torch.Tensor([0.47100772, 0.44772889, 0.01990966, 0.06135373])\n",
    "elif data_name == 'Image_after_2010_VA_256':\n",
    "    class_distr = torch.Tensor([0.37283283, 0.48029399, 0.04961892, 0.09725425])\n",
    "elif data_name == 'Image_allyear_VA_512':\n",
    "    class_distr = torch.Tensor([0.49843776, 0.45395527, 0.01021636, 0.03739061])\n",
    "elif data_name == 'Image_allyear_VA_256':\n",
    "    class_distr = torch.Tensor([0.47332474, 0.44650446, 0.02387324, 0.05629757])\n",
    "else:\n",
    "    raise\n",
    "\n",
    "def gen_weights(class_distribution, c = 1.02):\n",
    "    return 1/torch.log(c + class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f1c6729",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = data_name\n",
    "lr = 2e-3\n",
    "epo = 100\n",
    "backbone = 'vgg11'\n",
    "init_weights = 'imagenet'\n",
    "\n",
    "\n",
    "logname = 'unet_{}_{}_{}.log'.format(backbone, lr, data_source)\n",
    "dest_tensorboard = 'unet_{}_{}_{}'.format(backbone, lr, data_source)\n",
    "\n",
    "logging.basicConfig(filename=os.path.join(root_path, 'logs_backbone_paper', logname), filemode='a',level=logging.INFO, format='%(name)s - %(levelname)s - %(message)s')\n",
    "logging.info('*'*10)\n",
    "\n",
    "tempout_dir = up(path_cur)\n",
    "\n",
    "options = {'mode': 'train', 'epochs':epo, 'batch': 32, 'resume_from_epoch': 0,\n",
    "          'input_channels': 3, 'output_channels': 4, 'hidden_channels': 16, 'weight_param': 1.03,\n",
    "          'lr': lr, 'decay': 0, 'reduce_lr_on_plateau': 1, 'lr_steps':'[40]', \n",
    "          'checkpoint_root_path': tempout_dir, 'eval_every': 1,'data_source': data_source,\n",
    "          'backbone': backbone, 'dest_tensorboard': dest_tensorboard,\n",
    "          'encoder_weights': init_weights}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10ae64d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image_allyear_merged_512\n",
    "# Image_after_2010_merged_512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c04d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rapids/notebooks/sciclone/geograd/Miranda/github/shoreline_structure/datasets/Image_allyear_VA_256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load train set to memory: 100%|██████████| 1018/1018 [00:13<00:00, 74.45it/s]\n",
      "Load val set to memory:   2%|▏         | 6/255 [00:00<00:04, 54.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rapids/notebooks/sciclone/geograd/Miranda/github/shoreline_structure/datasets/Image_allyear_VA_256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load val set to memory: 100%|██████████| 255/255 [00:02<00:00, 95.30it/s] \n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.84it/s]\n",
      "testing: 100%|██████████| 8/8 [00:00<00:00,  8.09it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.79it/s]\n",
      "testing: 100%|██████████| 8/8 [00:00<00:00,  8.15it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.74it/s]\n",
      "testing: 100%|██████████| 8/8 [00:01<00:00,  7.15it/s]\n",
      "/opt/conda/envs/vims/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.79it/s]\n",
      "testing: 100%|██████████| 8/8 [00:01<00:00,  7.67it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.78it/s]\n",
      "testing: 100%|██████████| 8/8 [00:01<00:00,  7.92it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.79it/s]\n",
      "testing: 100%|██████████| 8/8 [00:00<00:00,  8.31it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.75it/s]\n",
      "testing: 100%|██████████| 8/8 [00:01<00:00,  7.75it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.79it/s]\n",
      "testing: 100%|██████████| 8/8 [00:00<00:00,  8.30it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.79it/s]\n",
      "testing: 100%|██████████| 8/8 [00:01<00:00,  6.98it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.80it/s]\n",
      "testing: 100%|██████████| 8/8 [00:00<00:00,  8.58it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.79it/s]\n",
      "testing: 100%|██████████| 8/8 [00:00<00:00,  8.08it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.81it/s]\n",
      "testing: 100%|██████████| 8/8 [00:00<00:00,  8.18it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.78it/s]\n",
      "testing: 100%|██████████| 8/8 [00:00<00:00,  8.10it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.80it/s]\n",
      "testing: 100%|██████████| 8/8 [00:00<00:00,  8.32it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.81it/s]\n",
      "testing: 100%|██████████| 8/8 [00:00<00:00,  8.57it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.76it/s]\n",
      "testing: 100%|██████████| 8/8 [00:01<00:00,  7.72it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.76it/s]\n",
      "testing: 100%|██████████| 8/8 [00:00<00:00,  8.11it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.73it/s]\n",
      "testing: 100%|██████████| 8/8 [00:00<00:00,  8.18it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.77it/s]\n",
      "testing: 100%|██████████| 8/8 [00:01<00:00,  7.19it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.78it/s]\n",
      "testing: 100%|██████████| 8/8 [00:01<00:00,  7.52it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.74it/s]\n",
      "testing: 100%|██████████| 8/8 [00:01<00:00,  7.88it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.78it/s]\n",
      "testing: 100%|██████████| 8/8 [00:00<00:00,  8.61it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.77it/s]\n",
      "testing: 100%|██████████| 8/8 [00:00<00:00,  8.12it/s]\n",
      "training:   0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00023: reducing learning rate of group 0 to 2.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.79it/s]\n",
      "testing: 100%|██████████| 8/8 [00:01<00:00,  7.96it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.77it/s]\n",
      "testing: 100%|██████████| 8/8 [00:00<00:00,  8.29it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.81it/s]\n",
      "testing: 100%|██████████| 8/8 [00:00<00:00,  8.19it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.77it/s]\n",
      "testing: 100%|██████████| 8/8 [00:00<00:00,  8.19it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.77it/s]\n",
      "testing: 100%|██████████| 8/8 [00:01<00:00,  7.48it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.73it/s]\n",
      "testing: 100%|██████████| 8/8 [00:01<00:00,  7.94it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.75it/s]\n",
      "testing: 100%|██████████| 8/8 [00:01<00:00,  7.14it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.76it/s]\n",
      "testing: 100%|██████████| 8/8 [00:00<00:00,  8.36it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.71it/s]\n",
      "testing: 100%|██████████| 8/8 [00:00<00:00,  8.20it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.78it/s]\n",
      "testing: 100%|██████████| 8/8 [00:01<00:00,  7.86it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.78it/s]\n",
      "testing: 100%|██████████| 8/8 [00:01<00:00,  7.88it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.77it/s]\n",
      "testing: 100%|██████████| 8/8 [00:01<00:00,  7.36it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.80it/s]\n",
      "testing: 100%|██████████| 8/8 [00:00<00:00,  8.33it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.78it/s]\n",
      "testing: 100%|██████████| 8/8 [00:00<00:00,  8.02it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.78it/s]\n",
      "testing: 100%|██████████| 8/8 [00:00<00:00,  8.18it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.75it/s]\n",
      "testing: 100%|██████████| 8/8 [00:00<00:00,  8.02it/s]\n",
      "training: 100%|██████████| 32/32 [00:11<00:00,  2.74it/s]\n",
      "testing: 100%|██████████| 8/8 [00:01<00:00,  7.21it/s]\n"
     ]
    }
   ],
   "source": [
    "main(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3691bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b1dbbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc38b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vims",
   "language": "python",
   "name": "vims"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
